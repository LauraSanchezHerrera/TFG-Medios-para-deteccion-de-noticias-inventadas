{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "informed-order",
   "metadata": {},
   "source": [
    "Este fichero contiene el método **buscar_una_noticia** que se encarga de **buscar todas las noticias con las que está relacionada la noticia buscada**. Por argumento se recibe el periódico y el número de la noticia buscada. Los pasos que sigue esta función están explicados paso a paso en el fichero **buscar_una_noticia.ipynb**.\n",
    "\n",
    "Además, al final de este fichero se llama al método **buscar_una_noticia** para **todas las noticias de la base de datos**, realizando así el primer filtrado. Tras esto, lo que se obtiene es **cada noticia con que otras noticias está relacionadas**, de esta manera será **más fácil encontrar conjuntos más pequeños de noticias relacionadas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proprietary-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metodo que se encarga de buscar las noticias con las que tiene relacion la noticia buscada\n",
    "def buscar_una_noticia(periodico_buscado, num_noticia_buscada):\n",
    "    # Librerias utilizadas\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    # Guardo en una variable todas las noticias del periodico_buscado que he obtenido\n",
    "    noticias_periodico_buscado = {}\n",
    "    url_noticias_periodico_buscado = 'Noticias/' + periodico_buscado + '/noticias.json'\n",
    "    with open(url_noticias_periodico_buscado) as file:\n",
    "        noticias_periodico_buscado = json.load(file)\n",
    "    \n",
    "    # Guardo las noticias recopiladas de cada periodico en una variable diferente\n",
    "    # EL MUNDO\n",
    "    noticias_periodico_ELMUNDO = {}\n",
    "    url_noticias_periodico_ELMUNDO = 'Noticias/EL MUNDO/noticias.json'\n",
    "    with open(url_noticias_periodico_ELMUNDO) as file:\n",
    "        noticias_periodico_ELMUNDO = json.load(file)\n",
    "\n",
    "    # 20 minutos\n",
    "    noticias_periodico_20minutos = {}\n",
    "    url_noticias_periodico_20minutos = 'Noticias/20 minutos/noticias.json'\n",
    "    with open(url_noticias_periodico_20minutos) as file:\n",
    "        noticias_periodico_20minutos = json.load(file)\n",
    "\n",
    "    # elEconomista.es\n",
    "    noticias_periodico_elEconomistaes = {}\n",
    "    url_noticias_periodico_elEconomistaes = 'Noticias/elEconomista.es/noticias.json'\n",
    "    with open(url_noticias_periodico_elEconomistaes) as file:\n",
    "        noticias_periodico_elEconomistaes = json.load(file)\n",
    "\n",
    "    # La Informacion\n",
    "    noticias_periodico_LaInformacion = {}\n",
    "    url_noticias_periodico_LaInformacion = 'Noticias/La Informacion/noticias.json'\n",
    "    with open(url_noticias_periodico_LaInformacion) as file:\n",
    "        noticias_periodico_LaInformacion = json.load(file)\n",
    "\n",
    "    # El Confidencial\n",
    "    noticias_periodico_ElConfidencial = {}\n",
    "    url_noticias_periodico_ElConfidencial = 'Noticias/El Confidencial/noticias.json'\n",
    "    with open(url_noticias_periodico_ElConfidencial) as file:\n",
    "        noticias_periodico_ElConfidencial = json.load(file)\n",
    "    \n",
    "    # Librerias utilizadas para construir la matriz de distancias\n",
    "    import numpy as np\n",
    "    from ipynb.fs.full.NCD import NCD # Funcion para calcular la NCD\n",
    "    from ipynb.fs.full.NCD import write_file_str #Funcion para escribir el contenido de una noticia a un fichero txt\n",
    "\n",
    "    # Escribo el contenido de la noticia buscada en un fichero txt para compararla con las otras noticias\n",
    "    filename_noticia_buscada = \"noticia_buscada.txt\" # Fichero txt para escribir el contenido de la noticia buscada\n",
    "    longitud_busqueda = len(noticias_periodico_buscado[num_noticia_buscada]['contenido']) # Tamaño noticia buscada\n",
    "    nombre_noticia_buscada = periodico_buscado + \"-\" + num_noticia_buscada\n",
    "\n",
    "    # Compruebo que la noticia buscada no es demasiado corta\n",
    "    indicador_noticia_demasiado_corta = 0\n",
    "    if longitud_busqueda < 1250:\n",
    "        indicador_noticia_demasiado_corta += 1\n",
    "        return # No hay que calcular nada, se descarta por ser demasiado corta\n",
    "    \n",
    "    # Escribo el contenido de la noticia en un fichero\n",
    "    write_file_str(filename_noticia_buscada, noticias_periodico_buscado[num_noticia_buscada]['contenido']) \n",
    "\n",
    "    # Fichero txt para escribir el contenido de la noticia que voy a comparar\n",
    "    filename_noticia_comparada = \"noticia_comparada.txt\" \n",
    "\n",
    "    dicc_periodico_noticias = {} # Diccionario para almacenar las noticias de cada periodico\n",
    "    dicc_periodico_noticias['EL MUNDO'] = noticias_periodico_ELMUNDO\n",
    "    dicc_periodico_noticias['20 minutos'] = noticias_periodico_20minutos\n",
    "    dicc_periodico_noticias['elEconomista.es'] = noticias_periodico_elEconomistaes\n",
    "    dicc_periodico_noticias['La Informacion'] = noticias_periodico_LaInformacion\n",
    "    dicc_periodico_noticias['El Confidencial'] = noticias_periodico_ElConfidencial\n",
    "\n",
    "\n",
    "    # Variables para hacer un estudio de las noticias que finalmente se han comparado\n",
    "    dicc_periodico_num_noticias = {} # Se va a almacenar para cada periodico el numero de noticias comparadas con la buscada\n",
    "    dicc_periodico_num_noticias['EL MUNDO'] = 0\n",
    "    dicc_periodico_num_noticias['20 minutos'] = 0\n",
    "    dicc_periodico_num_noticias['elEconomista.es'] = 0\n",
    "    dicc_periodico_num_noticias['La Informacion'] = 0\n",
    "    dicc_periodico_num_noticias['El Confidencial'] = 0\n",
    "\n",
    "    matriz_NCDs = {} # Diccionario donde voy a ir guardando los valores de las distancias\n",
    "    contador_dependencias = 0 # Cuenta el numero de noticias que son parecidas a la noticia buscada\n",
    "\n",
    "    # Recorro para cada periodico todas las noticias\n",
    "    for periodico in dicc_periodico_noticias:\n",
    "        for noticia in dicc_periodico_noticias[periodico]:\n",
    "            # Comparo la noticia con la noticia buscada (solo si no es la misma)\n",
    "            if periodico != periodico_buscado or noticia != num_noticia_buscada:\n",
    "\n",
    "                longitud_comparada = len(dicc_periodico_noticias[periodico][noticia]['contenido']) # Tamaño noticia comparada\n",
    "\n",
    "                # Solo comparo la noticia si su contenido no esta vacio y si tiene una longitud mayor de 1250\n",
    "                if dicc_periodico_noticias[periodico][noticia]['contenido'] != \"\" and longitud_comparada >= 1250:\n",
    "                    # Ademas tiene que tener una longitud parecida con la noticia buscada\n",
    "                    if longitud_busqueda + 1000 >= longitud_comparada and longitud_busqueda - 1000 <= longitud_comparada:\n",
    "\n",
    "                        dicc_periodico_num_noticias[periodico] += 1 # Cuento las noticias comparadas\n",
    "                        nombre_noticia_comparada = periodico + \"-\" + noticia\n",
    "\n",
    "                        # Escribo el contenido de la noticia comparada en un fichero txt para compararla con la noticia buscada\n",
    "                        write_file_str(filename_noticia_comparada, dicc_periodico_noticias[periodico][noticia]['contenido']) # Escribo el contenido en un fichero\n",
    "\n",
    "                        # Calculo las distancias de compresion normalizadas: NCD(noticia_buscada, noticia_comparada) y NCD(noticia_comparada, noticia_buscada)\n",
    "                        NCDs = NCD(filename_noticia_buscada, filename_noticia_comparada)\n",
    "\n",
    "                        # Quiero de alguna manera identificar las noticias con mas similitud a otras y las que menos\n",
    "                        # Para ello voy a contar las veces que:\n",
    "                        # n1 --> n2 < 0,765 y n2 --> n1 < 0,8\n",
    "                        # o\n",
    "                        # n2 --> n1 < 0,765 y n1 --> n2 < 0,8\n",
    "                        # o\n",
    "                        # n2 --> n1 < 0,765 y n1 --> n2 < 0,765\n",
    "                        # Es decir, al menos una de las distancias debe ser < 0,765 y la otra < 0,8\n",
    "                        if ((NCDs[0] < 0.765 and NCDs[1] < 0.8) or (NCDs[1] < 0.765 and NCDs[0] < 0.8)):\n",
    "                            contador_dependencias += 1 # Aumento el valor de noticias similares encontradas\n",
    "\n",
    "                        # Guardo los resultados en la matriz de distancias\n",
    "\n",
    "                        # noticia_buscada - noticia_comparada\n",
    "                        if nombre_noticia_buscada not in matriz_NCDs:\n",
    "                            matriz_NCDs[nombre_noticia_buscada] = {}\n",
    "                            matriz_NCDs[nombre_noticia_buscada][nombre_noticia_comparada] = NCDs[0]\n",
    "                        else:\n",
    "                            matriz_NCDs[nombre_noticia_buscada][nombre_noticia_comparada] = NCDs[0]\n",
    "\n",
    "                        # noticia_comparada - noticia_buscada\n",
    "                        if nombre_noticia_comparada not in matriz_NCDs:\n",
    "                            matriz_NCDs[nombre_noticia_comparada] = {}\n",
    "                            matriz_NCDs[nombre_noticia_comparada][nombre_noticia_buscada] = NCDs[1]\n",
    "                        else:\n",
    "                            matriz_NCDs[nombre_noticia_comparada][nombre_noticia_buscada] = NCDs[1]\n",
    "                            \n",
    "    import math\n",
    "\n",
    "    # Calculo el numero de noticias que se han comparado\n",
    "    # Antes compruebo que se haya comparado con alguna noticia\n",
    "    if nombre_noticia_buscada not in matriz_NCDs:\n",
    "        return #No se ha podido comparar por el tamaño, acaba la funcion\n",
    "    numero_noticias_comparadas = len(matriz_NCDs[nombre_noticia_buscada])\n",
    "    # Para que el resultado sea legible es necesario dividir las distancias en varias matrices de distancia\n",
    "    # Se ha decidido que para un conjunto de 50 noticias el dendograma resultando se puede estudiar bien\n",
    "    # Hay que tener en cuenta que en todas las matrices debe estar la noticia buscada, ya que es la que se esta comparando\n",
    "    numero_matrices_distancia = numero_noticias_comparadas / 50\n",
    "\n",
    "    # Creo las matrices de distancia que sean necesarias\n",
    "\n",
    "    list_matrices = [] # lista de matrices\n",
    "    list_posiciones = [] # lista de posiciones en cada matriz\n",
    "    contador_noticias_comparadas_matriz = 0 # Indica el numero de noticias comparadas que ya han sido añadidas en matrices\n",
    "\n",
    "    for numero_matriz in range(0,math.ceil(numero_matrices_distancia)):\n",
    "\n",
    "        matriz_distancias_noticia_buscada_sin_numpy = [] # Estrutura para crear la matriz de distancias\n",
    "\n",
    "        # Contenido inicial de cada fila de la matriz, tiene 50 (noticia_buscada + 49 noticias_comparadas) columnas\n",
    "        # Primero pongo todo a 1\n",
    "        for fila in range(0, 50):\n",
    "            list_aux = []\n",
    "            for columna in range(0, 50):  \n",
    "                list_aux.append(1)\n",
    "            matriz_distancias_noticia_buscada_sin_numpy.append(list_aux)\n",
    "            \n",
    "        # Es necesario guardar las posiciones porque en el dendograma final aparecen numeradas las noticias segun\n",
    "        # su posicion en la matriz, pero no se puede identificar la noticia que es\n",
    "\n",
    "        # Guarda la posicion de cada noticia en la matriz\n",
    "        posicion_noticia_matriz = [nombre_noticia_buscada] # la primera siempre es la noticia_buscada \n",
    "\n",
    "        # Guardo la posicion de cada noticia en la matriz\n",
    "        aux_contador_noticias_comparadas_matriz = contador_noticias_comparadas_matriz\n",
    "        limite = contador_noticias_comparadas_matriz + 49 # Indica hasta que noticia_comparada tengo que leer\n",
    "        cont = 1\n",
    "        for nombre_noticia_comparada in matriz_NCDs[nombre_noticia_buscada]:\n",
    "            if cont > limite:\n",
    "                break\n",
    "            if cont > contador_noticias_comparadas_matriz:\n",
    "                posicion_noticia_matriz.append(nombre_noticia_comparada)\n",
    "                contador_noticias_comparadas_matriz += 1\n",
    "            cont += 1\n",
    "\n",
    "        # Relleno con ceros la diagonal de la matriz ya que una noticia y la misma, son iguales\n",
    "        cont_fila = 0\n",
    "        for fila in matriz_distancias_noticia_buscada_sin_numpy:\n",
    "            fila[cont_fila] = 0\n",
    "            cont_fila += 1\n",
    "\n",
    "        # Relleno con las distancias calculadas\n",
    "\n",
    "        # Primero noticia_buscada --> noticia_comparada\n",
    "        cont_columna = 1\n",
    "        cont = 1\n",
    "        for nombre_noticia_comparada in matriz_NCDs[nombre_noticia_buscada]:\n",
    "            if cont > limite:\n",
    "                break\n",
    "            if cont > aux_contador_noticias_comparadas_matriz:\n",
    "                matriz_distancias_noticia_buscada_sin_numpy[0][cont_columna] = matriz_NCDs[nombre_noticia_buscada][nombre_noticia_comparada]\n",
    "                cont_columna += 1\n",
    "            cont += 1\n",
    "\n",
    "        # Segundo noticia_comparada --> noticia_buscada\n",
    "        cont_fila = 1\n",
    "        cont = 1\n",
    "        for nombre_noticia_comparada in matriz_NCDs[nombre_noticia_buscada]:\n",
    "            if cont > limite:\n",
    "                break\n",
    "            if cont > aux_contador_noticias_comparadas_matriz:\n",
    "                matriz_distancias_noticia_buscada_sin_numpy[cont_fila][0] = matriz_NCDs[nombre_noticia_comparada][nombre_noticia_buscada]\n",
    "                cont_fila += 1\n",
    "            cont += 1\n",
    "\n",
    "        \n",
    "        matriz_distancias_noticia_buscada = np.array(matriz_distancias_noticia_buscada_sin_numpy)\n",
    "\n",
    "        # Guardo la matriz y las posiciones\n",
    "        list_matrices.append(matriz_distancias_noticia_buscada)\n",
    "        list_posiciones.append(posicion_noticia_matriz)\n",
    "        \n",
    "    # Gráficos\n",
    "    # ==============================================================================\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import style\n",
    "    style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "    # Preprocesado y modelado\n",
    "    # ==============================================================================\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    from scipy.cluster.hierarchy import dendrogram\n",
    "    from sklearn.preprocessing import scale\n",
    "    from sklearn.metrics import silhouette_score\n",
    "\n",
    "    # Ficheros donde guardar los datos si la noticia no es demasiado corta\n",
    "    if indicador_noticia_demasiado_corta == 0:\n",
    "        # Carpeta raiz de todos los datos\n",
    "        if not os.path.exists('Noticias/Base de datos'):\n",
    "            os.mkdir('Noticias/Base de datos')\n",
    "\n",
    "        # Carpeta segun el numero de dependencias para diferencias segun las noticias con mas dependencias\n",
    "        if not os.path.exists('Noticias/Base de datos/' + str(contador_dependencias)):\n",
    "            os.mkdir('Noticias/Base de datos/' + str(contador_dependencias))\n",
    "\n",
    "        # Carpeta para cada noticia buscada\n",
    "        if not os.path.exists('Noticias/Base de datos/' + str(contador_dependencias) + '/' + nombre_noticia_buscada):\n",
    "            os.mkdir('Noticias/Base de datos/' + str(contador_dependencias) + '/' + nombre_noticia_buscada)\n",
    "        carpeta_noticia_buscada = 'Noticias/Base de datos/' + str(contador_dependencias) + '/' + nombre_noticia_buscada\n",
    "\n",
    "    # Funcion para dibujar graficas\n",
    "    def plot_dendrogram(model, **kwargs):\n",
    "        '''\n",
    "        Esta función extrae la información de un modelo AgglomerativeClustering\n",
    "        y representa su dendograma con la función dendogram de scipy.cluster.hierarchy\n",
    "        '''\n",
    "\n",
    "        counts = np.zeros(model.children_.shape[0])\n",
    "        n_samples = len(model.labels_)\n",
    "        for i, merge in enumerate(model.children_):\n",
    "            current_count = 0\n",
    "            for child_idx in merge:\n",
    "                if child_idx < n_samples:\n",
    "                    current_count += 1  # leaf node\n",
    "                else:\n",
    "                    current_count += counts[child_idx - n_samples]\n",
    "            counts[i] = current_count\n",
    "\n",
    "        linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                          counts]).astype(float)\n",
    "\n",
    "        # Plot\n",
    "        dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "    # Creo un cluster por cada matriz de distancias\n",
    "    for numero_matriz in range(0,math.ceil(numero_matrices_distancia)):\n",
    "        # Modelo utilizado\n",
    "        # ==============================================================================\n",
    "        modelo_hclust_complete = AgglomerativeClustering(\n",
    "                                    affinity = 'precomputed',\n",
    "                                    linkage  = 'single',\n",
    "                                    distance_threshold = 0,\n",
    "                                    n_clusters         = None\n",
    "                                )\n",
    "        modelo_hclust_complete.fit(X=list_matrices[numero_matriz])\n",
    "\n",
    "        # Dendrograma\n",
    "        # ==============================================================================\n",
    "        fig, figura = plt.subplots(1, 1, figsize=(20,8))\n",
    "        plot_dendrogram(modelo_hclust_complete, color_threshold=0, ax=figura)\n",
    "        figura.set_title(\"Distancia NCD, Linkage single, matriz \" + str(numero_matriz))\n",
    "        plt.tight_layout();\n",
    "\n",
    "        # Guardo los datos\n",
    "        # ==============================================================================\n",
    "        # Solo guardo los datos si la noticia no es demasiado corta\n",
    "        if indicador_noticia_demasiado_corta == 0:\n",
    "            # Cluster\n",
    "            nombre_imagen = carpeta_noticia_buscada + \"/Cluster \" + str(numero_matriz) + \".jpg\"\n",
    "            plt.savefig(nombre_imagen)\n",
    "            # Matrices de distancia\n",
    "            # Solo tiene distancias la primera fila y primera columna. Se compara la noticia_buscada con el resto\n",
    "            nombre_matrices = carpeta_noticia_buscada + \"/Matriz \" + str(numero_matriz) + \".json\"\n",
    "            with open(nombre_matrices, 'w') as fp:\n",
    "                json.dump(list_matrices[numero_matriz].tolist(), fp)\n",
    "\n",
    "            # Lista de posiciones\n",
    "            # Posicion de la lista = fila en la matriz, la primera fila es de la noticia_buscada\n",
    "            nombre_posiciones = carpeta_noticia_buscada + \"/Posicion \" + str(numero_matriz) + \".json\"\n",
    "            with open(nombre_posiciones, 'w') as fp:\n",
    "                json.dump(list_posiciones[numero_matriz], fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-postage",
   "metadata": {},
   "source": [
    "Se llama al método **buscar_una_noticia** para **todas las noticias de la base de datos**, realizando así el primer filtrado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero la base de datos comparando todas las noticias\n",
    "# Guardo las noticias recopiladas de cada periodico en una variable diferente\n",
    "import json\n",
    "import os\n",
    "\n",
    "# EL MUNDO\n",
    "noticias_periodico_ELMUNDO = {}\n",
    "url_noticias_periodico_ELMUNDO = 'Noticias/EL MUNDO/noticias.json'\n",
    "with open(url_noticias_periodico_ELMUNDO) as file:\n",
    "    noticias_periodico_ELMUNDO = json.load(file)\n",
    "    \n",
    "# 20 minutos\n",
    "noticias_periodico_20minutos = {}\n",
    "url_noticias_periodico_20minutos = 'Noticias/20 minutos/noticias.json'\n",
    "with open(url_noticias_periodico_20minutos) as file:\n",
    "    noticias_periodico_20minutos = json.load(file)\n",
    "    \n",
    "# elEconomista.es\n",
    "noticias_periodico_elEconomistaes = {}\n",
    "url_noticias_periodico_elEconomistaes = 'Noticias/elEconomista.es/noticias.json'\n",
    "with open(url_noticias_periodico_elEconomistaes) as file:\n",
    "    noticias_periodico_elEconomistaes = json.load(file)\n",
    "    \n",
    "# La Informacion\n",
    "noticias_periodico_LaInformacion = {}\n",
    "url_noticias_periodico_LaInformacion = 'Noticias/La Informacion/noticias.json'\n",
    "with open(url_noticias_periodico_LaInformacion) as file:\n",
    "    noticias_periodico_LaInformacion = json.load(file)\n",
    "    \n",
    "# El Confidencial\n",
    "noticias_periodico_ElConfidencial = {}\n",
    "url_noticias_periodico_ElConfidencial = 'Noticias/El Confidencial/noticias.json'\n",
    "with open(url_noticias_periodico_ElConfidencial) as file:\n",
    "    noticias_periodico_ElConfidencial = json.load(file)\n",
    "    \n",
    "\n",
    "dicc_periodico_noticias = {} # Diccionario para almacenar las noticias de cada periodico\n",
    "dicc_periodico_noticias['EL MUNDO'] = noticias_periodico_ELMUNDO # todas\n",
    "dicc_periodico_noticias['20 minutos'] = noticias_periodico_20minutos # todas\n",
    "dicc_periodico_noticias['elEconomista.es'] = noticias_periodico_elEconomistaes #todas\n",
    "dicc_periodico_noticias['La Informacion'] = noticias_periodico_LaInformacion #todas\n",
    "dicc_periodico_noticias['El Confidencial'] = noticias_periodico_ElConfidencial #ha llegado a la 33\n",
    "\n",
    "# Recorro para cada periodico todas las noticias\n",
    "for periodico in dicc_periodico_noticias:\n",
    "    for noticia in dicc_periodico_noticias[periodico]:\n",
    "        print(periodico + \" - \" + noticia)\n",
    "        buscar_una_noticia(periodico, noticia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
